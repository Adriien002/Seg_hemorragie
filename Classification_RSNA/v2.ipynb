{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset ready with 539469 samples and cached transforms at persistent_cache/fold0\n"
     ]
    }
   ],
   "source": [
    "from monai.data import PersistentDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import monai.transforms as T\n",
    "import torch\n",
    "# Using MONAI for medical imaging tasks\n",
    "# ---- Config ----\n",
    "csv_path = Path(\"/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/csv/train_fold0.csv\")\n",
    "dicom_dir = Path(\"/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/rsna-intracranial-hemorrhage-detection/stage_2_train\")\n",
    "cache_dir = Path(\"./persistent_cache/fold0\")  \n",
    "\n",
    "label_cols = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ---- Build MONAI-style data list ----\n",
    "data_list = [\n",
    "    {\n",
    "        \"image\": str(dicom_dir / row['filename']),\n",
    "        \"label\": np.array([row[col] for col in label_cols], dtype=np.float32)\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "#print (data_list[:5] ) # Print first 5 entries for debugging\n",
    "# ---- Transforms ----\n",
    "window_preset = {\"window_center\": 40, \"window_width\": 80}\n",
    "\n",
    "\n",
    "window_preset = {\"window_center\": 40, \"window_width\": 80}\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    T.LoadImaged(keys=[\"image\"],image_only=True ),\n",
    "    T.ScaleIntensityRanged(\n",
    "        keys=[\"image\"],\n",
    "        a_min=window_preset[\"window_center\"] - window_preset[\"window_width\"] // 2,\n",
    "        a_max=window_preset[\"window_center\"] + window_preset[\"window_width\"] // 2,\n",
    "        b_min=0.0,\n",
    "        b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "    T.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    T.ResizeD(keys=[\"image\"], spatial_size=(224, 224)),\n",
    "    T.ToTensord(keys=[\"image\", \"label\"])  \n",
    "])\n",
    "\n",
    "\n",
    "# ---- PersistentDataset ----\n",
    "train_dataset = PersistentDataset(\n",
    "    data=data_list,\n",
    "    transform=train_transforms,\n",
    "    cache_dir=str(cache_dir),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Dataset ready with {len(train_dataset)} samples and cached transforms at {cache_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of Batches in the dataset: 16859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "répartition des poids : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from monai.networks.nets import densenet121,SEResNet50,ResNet\n",
    "from monai.transforms import Compose, Resize, ToTensor\n",
    "from monai.data import DataLoader, PersistentDataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# === Hyperparams ===\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LR = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8,persistent_workers= True,pin_memory=True)\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Number of Batches in the dataset: {len(train_loader)}\")\n",
    "\n",
    "# === Model ===\n",
    "model = ResNet(\n",
    "    block='basic',           # BasicBlock for ResNet18/34\n",
    "    layers=[2, 2, 2, 2],    # ResNet18 architecture\n",
    "    block_inplanes=[64, 128, 256, 512],\n",
    "    spatial_dims=2,\n",
    "    n_input_channels=1,     # Your grayscale input\n",
    "    num_classes=NUM_CLASSES,\n",
    "    conv1_t_size=7,\n",
    "    conv1_t_stride=2\n",
    ")\n",
    "# model = SEResNet50(\n",
    "#     spatial_dims=2,         # Because you work with 2D CT slices\n",
    "#     in_channels=1,          # 1 channel for grayscale CT (unless you use 3-slice input, see tip below)\n",
    "#     num_classes= NUM_CLASSES,          # Set this to number of hemorrhage types you want to classify\n",
    "#     pretrained=False,       # Can be True if input has 3 channels and you're okay fine-tuning from ImageNet\n",
    "#     dropout_prob=0.2,       # Helps regularize on smaller datasets\n",
    "#     reduction=16,           # Default for Squeeze-and-Excitation; works well\n",
    "#     input_3x3=True,         # Enables better local feature extraction at first layer\n",
    "#     downsample_kernel_size=3  # Slightly better spatial feature preservation\n",
    "#)\n",
    "#model = densenet121(spatial_dims=2, in_channels=1, out_channels=NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "#print (model)\n",
    "# === Loss (Inspiré Al )\n",
    "\n",
    "pos_weights = torch.tensor([1.0] * NUM_CLASSES, dtype=torch.float).to(DEVICE)\n",
    "print(f\"répartition des poids : {pos_weights}\")\n",
    "loss_fn= nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "# === Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /store/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [32, 6]                   --\n",
       "├─Conv2d: 1-1                            [32, 64, 112, 112]        3,136\n",
       "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        128\n",
       "├─ReLU: 1-3                              [32, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [32, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [32, 64, 56, 56]          --\n",
       "│    └─ResNetBlock: 2-1                  [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          --\n",
       "│    └─ResNetBlock: 2-2                  [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-7                  [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-9                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-10                 [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-12                   [32, 64, 56, 56]          --\n",
       "├─Sequential: 1-6                        [32, 128, 28, 28]         --\n",
       "│    └─ResNetBlock: 2-3                  [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-13                 [32, 128, 28, 28]         73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [32, 128, 28, 28]         256\n",
       "│    │    └─ReLU: 3-15                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-16                 [32, 128, 28, 28]         147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [32, 128, 28, 28]         256\n",
       "│    │    └─Sequential: 3-18             [32, 128, 28, 28]         8,576\n",
       "│    │    └─ReLU: 3-19                   [32, 128, 28, 28]         --\n",
       "│    └─ResNetBlock: 2-4                  [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-20                 [32, 128, 28, 28]         147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [32, 128, 28, 28]         256\n",
       "│    │    └─ReLU: 3-22                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-23                 [32, 128, 28, 28]         147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [32, 128, 28, 28]         256\n",
       "│    │    └─ReLU: 3-25                   [32, 128, 28, 28]         --\n",
       "├─Sequential: 1-7                        [32, 256, 14, 14]         --\n",
       "│    └─ResNetBlock: 2-5                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-26                 [32, 256, 14, 14]         294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 256, 14, 14]         512\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-29                 [32, 256, 14, 14]         589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 256, 14, 14]         512\n",
       "│    │    └─Sequential: 3-31             [32, 256, 14, 14]         33,536\n",
       "│    │    └─ReLU: 3-32                   [32, 256, 14, 14]         --\n",
       "│    └─ResNetBlock: 2-6                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-33                 [32, 256, 14, 14]         589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [32, 256, 14, 14]         512\n",
       "│    │    └─ReLU: 3-35                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-36                 [32, 256, 14, 14]         589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [32, 256, 14, 14]         512\n",
       "│    │    └─ReLU: 3-38                   [32, 256, 14, 14]         --\n",
       "├─Sequential: 1-8                        [32, 512, 7, 7]           --\n",
       "│    └─ResNetBlock: 2-7                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-39                 [32, 512, 7, 7]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-41                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-42                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 512, 7, 7]           1,024\n",
       "│    │    └─Sequential: 3-44             [32, 512, 7, 7]           132,608\n",
       "│    │    └─ReLU: 3-45                   [32, 512, 7, 7]           --\n",
       "│    └─ResNetBlock: 2-8                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-46                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-48                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-49                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-51                   [32, 512, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [32, 512, 1, 1]           --\n",
       "├─Linear: 1-10                           [32, 6]                   3,078\n",
       "==========================================================================================\n",
       "Total params: 11,174,214\n",
       "Trainable params: 11,174,214\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 55.52\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 1271.66\n",
       "Params size (MB): 44.70\n",
       "Estimated Total Size (MB): 1322.78\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try : \n",
    "    ! pip install torchinfo\n",
    "\n",
    "except:\n",
    "    print(\"torchinfo is already installed or installation failed.\")\n",
    "    \n",
    "import torchinfo\n",
    "from torchinfo import summary\n",
    "# Display model summary\n",
    "model = model.to(DEVICE)\n",
    "summary(model, input_size=(BATCH_SIZE, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float,end:float,device:torch.device=None):\n",
    "    total_time=end-start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Renvoie l'accuracy multilabel (exact match pour chaque label indépendamment).\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(y_pred) > threshold\n",
    "    #print(f\"preds: {preds}\")\n",
    "    correct = (preds == y_true.bool()).float()\n",
    "    #print(f\"correct: {correct}\")\n",
    "    return correct.mean().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:torch.nn.Module,\n",
    "                dataloader:torch.utils.data.DataLoader,\n",
    "                loss_fn:torch.nn.Module,\n",
    "                optimizer:torch.optim,\n",
    "                compute_accuracy,\n",
    "                device:torch.device=DEVICE):\n",
    "   \n",
    "    train_loss,train_acc=0,0\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "      X = batch[\"image\"].to(device)\n",
    "      y = batch[\"label\"].to(device)\n",
    "    \n",
    "      #1. forward pass (output the raw logits from the model )\n",
    "      y_pred=model(X)\n",
    "\n",
    "      #2. Calculate loss and accuracy (per batch)\n",
    "      loss=loss_fn(y_pred,y)\n",
    "      train_loss += loss\n",
    "      train_acc += compute_accuracy(y_pred=y_pred,y_true=y) # go from logits -> prediction labels\n",
    "\n",
    "      #3. Optimizer zero grad \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      #4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      #5. Optimizer step\n",
    "      \n",
    "      optimizer.step()\n",
    "      #Divide total train loss and acc by lenght of train dataloader\n",
    "    \n",
    "      if (i% 400 == 0):\n",
    "        print(f\"Looked at {i * len(X)}/{len(dataloader.dataset)} samples\")\n",
    "      \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.4f}\")\n",
    "\n",
    "\n",
    "def val_step(model:torch.nn.Module,\n",
    "                dataloader:torch.utils.data.DataLoader,\n",
    "                loss_fn:torch.nn.Module,\n",
    "                compute_accuracy,\n",
    "                device:torch.device=DEVICE):\n",
    "    \"\"\"Performs a testing loop step on model going over data_loader\"\"\"\n",
    "   \n",
    "    test_loss,test_acc=0,0\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      for batch,(X_test,y_test) in enumerate(dataloader):\n",
    "     \n",
    "        X_test,y_test=X_test.to(device),y_test.to(device)\n",
    "\n",
    "      #1. forward pass (output the raw logits from the model )\n",
    "        test_pred=model(X_test)\n",
    "\n",
    "      #2. Calculate loss and accuracy (per batch)\n",
    "        loss=loss_fn(test_pred,y_test)\n",
    "        test_loss += loss\n",
    "        test_acc += compute_accuracy(y_true=y_test,y_pred=test_pred) # go from logits -> prediction labels\n",
    "     \n",
    "        if (batch % 400 == 0):\n",
    "          print(f\"Looked at {batch * len(X_test)}/{len(dataloader.dataset)} samples\")\n",
    "    #Divide total test loss and acc by lenght of test dataloader\n",
    "      test_loss /= len(dataloader)\n",
    "      test_acc /= len(dataloader)\n",
    "\n",
    "      print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n",
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n",
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n",
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n",
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n",
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n",
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n",
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(hashfile)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/539469 samples\n",
      "Looked at 12800/539469 samples\n",
      "Looked at 25600/539469 samples\n",
      "Looked at 38400/539469 samples\n",
      "Looked at 51200/539469 samples\n",
      "Looked at 64000/539469 samples\n",
      "Looked at 76800/539469 samples\n",
      "Looked at 89600/539469 samples\n",
      "Looked at 102400/539469 samples\n",
      "Looked at 115200/539469 samples\n",
      "Looked at 128000/539469 samples\n",
      "Looked at 140800/539469 samples\n",
      "Looked at 153600/539469 samples\n",
      "Looked at 166400/539469 samples\n",
      "Looked at 179200/539469 samples\n",
      "Looked at 192000/539469 samples\n",
      "Looked at 204800/539469 samples\n",
      "Looked at 217600/539469 samples\n",
      "Looked at 230400/539469 samples\n",
      "Looked at 243200/539469 samples\n",
      "Looked at 256000/539469 samples\n",
      "Looked at 268800/539469 samples\n",
      "Looked at 281600/539469 samples\n",
      "Looked at 294400/539469 samples\n",
      "Looked at 307200/539469 samples\n",
      "Looked at 320000/539469 samples\n",
      "Looked at 332800/539469 samples\n",
      "Looked at 345600/539469 samples\n",
      "Looked at 358400/539469 samples\n",
      "Looked at 371200/539469 samples\n",
      "Looked at 384000/539469 samples\n",
      "Looked at 396800/539469 samples\n",
      "Looked at 409600/539469 samples\n",
      "Looked at 422400/539469 samples\n",
      "Looked at 435200/539469 samples\n",
      "Looked at 448000/539469 samples\n",
      "Looked at 460800/539469 samples\n",
      "Looked at 473600/539469 samples\n",
      "Looked at 486400/539469 samples\n",
      "Looked at 499200/539469 samples\n",
      "Looked at 512000/539469 samples\n",
      "Looked at 524800/539469 samples\n",
      "Looked at 537600/539469 samples\n",
      "Train loss: 0.11931 | Train acc: 0.9578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [18:41<37:23, 1121.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/539469 samples\n",
      "Looked at 12800/539469 samples\n",
      "Looked at 25600/539469 samples\n",
      "Looked at 38400/539469 samples\n",
      "Looked at 51200/539469 samples\n",
      "Looked at 64000/539469 samples\n",
      "Looked at 76800/539469 samples\n",
      "Looked at 89600/539469 samples\n",
      "Looked at 102400/539469 samples\n",
      "Looked at 115200/539469 samples\n",
      "Looked at 128000/539469 samples\n",
      "Looked at 140800/539469 samples\n",
      "Looked at 153600/539469 samples\n",
      "Looked at 166400/539469 samples\n",
      "Looked at 179200/539469 samples\n",
      "Looked at 192000/539469 samples\n",
      "Looked at 204800/539469 samples\n",
      "Looked at 217600/539469 samples\n",
      "Looked at 230400/539469 samples\n",
      "Looked at 243200/539469 samples\n",
      "Looked at 256000/539469 samples\n",
      "Looked at 268800/539469 samples\n",
      "Looked at 281600/539469 samples\n",
      "Looked at 294400/539469 samples\n",
      "Looked at 307200/539469 samples\n",
      "Looked at 320000/539469 samples\n",
      "Looked at 332800/539469 samples\n",
      "Looked at 345600/539469 samples\n",
      "Looked at 358400/539469 samples\n",
      "Looked at 371200/539469 samples\n",
      "Looked at 384000/539469 samples\n",
      "Looked at 396800/539469 samples\n",
      "Looked at 409600/539469 samples\n",
      "Looked at 422400/539469 samples\n",
      "Looked at 435200/539469 samples\n",
      "Looked at 448000/539469 samples\n",
      "Looked at 460800/539469 samples\n",
      "Looked at 473600/539469 samples\n",
      "Looked at 486400/539469 samples\n",
      "Looked at 499200/539469 samples\n",
      "Looked at 512000/539469 samples\n",
      "Looked at 524800/539469 samples\n",
      "Looked at 537600/539469 samples\n",
      "Train loss: 0.09305 | Train acc: 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [50:41<26:31, 1591.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/539469 samples\n",
      "Looked at 12800/539469 samples\n",
      "Looked at 25600/539469 samples\n",
      "Looked at 38400/539469 samples\n",
      "Looked at 51200/539469 samples\n",
      "Looked at 64000/539469 samples\n",
      "Looked at 76800/539469 samples\n",
      "Looked at 89600/539469 samples\n",
      "Looked at 102400/539469 samples\n",
      "Looked at 115200/539469 samples\n",
      "Looked at 128000/539469 samples\n",
      "Looked at 140800/539469 samples\n",
      "Looked at 153600/539469 samples\n",
      "Looked at 166400/539469 samples\n",
      "Looked at 179200/539469 samples\n",
      "Looked at 192000/539469 samples\n",
      "Looked at 204800/539469 samples\n",
      "Looked at 217600/539469 samples\n",
      "Looked at 230400/539469 samples\n",
      "Looked at 243200/539469 samples\n",
      "Looked at 256000/539469 samples\n",
      "Looked at 268800/539469 samples\n",
      "Looked at 281600/539469 samples\n",
      "Looked at 294400/539469 samples\n",
      "Looked at 307200/539469 samples\n",
      "Looked at 320000/539469 samples\n",
      "Looked at 332800/539469 samples\n",
      "Looked at 345600/539469 samples\n",
      "Looked at 358400/539469 samples\n",
      "Looked at 371200/539469 samples\n",
      "Looked at 384000/539469 samples\n",
      "Looked at 396800/539469 samples\n",
      "Looked at 409600/539469 samples\n",
      "Looked at 422400/539469 samples\n",
      "Looked at 435200/539469 samples\n",
      "Looked at 448000/539469 samples\n",
      "Looked at 460800/539469 samples\n",
      "Looked at 473600/539469 samples\n",
      "Looked at 486400/539469 samples\n",
      "Looked at 499200/539469 samples\n",
      "Looked at 512000/539469 samples\n",
      "Looked at 524800/539469 samples\n",
      "Looked at 537600/539469 samples\n",
      "Train loss: 0.08151 | Train acc: 0.9709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [1:13:18<00:00, 1466.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cuda: 4399.478 seconds\n"
     ]
    }
   ],
   "source": [
    "# # === Training Loop ===\n",
    "# from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    train_step(model=model,\n",
    "               dataloader=train_loader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               compute_accuracy=compute_accuracy,\n",
    "               device=DEVICE)\n",
    "    \n",
    "\n",
    "end_time = timer()\n",
    "total_train_time = print_train_time(start_time, end_time, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemorragie-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
