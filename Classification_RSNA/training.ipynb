{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Test to understand __get_item__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first_item: <class 'dict'>\n",
      "Keys in first_item: dict_keys(['image', 'label'])\n",
      "Shape of first_item['image']: (64, 64)\n",
      "Dataset length: 3\n",
      "Processing item 0\n",
      "Processing item 1\n",
      "Processing item 2\n",
      "images path : ['img1.dcm', 'img2.dcm', 'img3.dcm']\n",
      "labels : [0, 1, 0]\n",
      "Transforms : None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class MyMedicalDataset:\n",
    "    def __init__(self, image_paths, labels, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        # When you do dataset[i], this method is called with idx = i\n",
    "\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # In a real scenario, you'd load the image (e.g., DICOM with pydicom/MONAI LoadImage)\n",
    "        # For simplicity, let's pretend we load a dummy image\n",
    "        image_data = np.random.rand(64, 64) # Simulate loading an image\n",
    "\n",
    "        # Apply transforms if provided (e.g., MONAI transforms)\n",
    "        if self.transforms:\n",
    "            # MONAI transforms expect dictionaries\n",
    "            data_dict = {\"image\": image_data, \"label\": label}\n",
    "            data_dict = self.transforms(data_dict)\n",
    "            image_data = data_dict[\"image\"]\n",
    "            label = data_dict[\"label\"]\n",
    "\n",
    "        return {\"image\": image_data, \"label\": label}\n",
    "\n",
    "# --- Usage Example ---\n",
    "image_files = [\"img1.dcm\", \"img2.dcm\", \"img3.dcm\"]\n",
    "labels_data = [0, 1, 0]\n",
    "\n",
    "# Imagine some MONAI transforms here\n",
    "from monai.transforms import RandFlip, Compose, AsDiscrete, EnsureChannelFirstd\n",
    "\n",
    " #my_transforms = Compose([\n",
    "#     EnsureChannelFirstd(keys=\"image\"),\n",
    "#     RandFlip(prob=0.5, spatial_axis=None)\n",
    "    \n",
    "# ])\n",
    "\n",
    "\n",
    "dataset = MyMedicalDataset(image_files, labels_data, transforms=None)\n",
    "\n",
    "# This calls dataset.__getitem__(0)\n",
    "first_item = dataset[0]\n",
    "print(f\"Type of first_item: {type(first_item)}\")\n",
    "print(f\"Keys in first_item: {first_item.keys()}\")\n",
    "print(f\"Shape of first_item['image']: {first_item['image'].shape}\")\n",
    "\n",
    "# This calls dataset.__len__()\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "\n",
    "# This indirectly uses __getitem__ (and __len__) for iteration\n",
    "for i in range(len(dataset)):\n",
    "    item = dataset[i]\n",
    "    print(f\"Processing item {i}\")\n",
    "\n",
    "# Test on the class itself \n",
    "print(f\"images path : {dataset.image_paths}\" )\n",
    "print(f\"labels : {dataset.labels}\")\n",
    "print(f\"Transforms : {dataset.transforms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pydicom\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class RSNA_DICOM_Dataset(Dataset):\n",
    "    def __init__(self, csv_path, dicom_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.dicom_dir = Path(dicom_dir)\n",
    "        self.transform = transform\n",
    "        self.label_cols = [ 'any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        self.loader = T.LoadImage(image_only=False)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        dcm_path = self.dicom_dir / row['filename']\n",
    "        dcm = pydicom.dcmread(str(dcm_path))\n",
    "\n",
    "        # Load image\n",
    "        image, meta = self.loader(str(dcm_path)) # Using MONAI's LoadImage\n",
    "\n",
    "        dicom_raw = pydicom.dcmread(str(dcm_path))\n",
    "\n",
    "        center = int(dicom_raw.WindowCenter)\n",
    "        width = int(dicom_raw.WindowWidth)\n",
    "        slope = float(dicom_raw.RescaleSlope)\n",
    "        intercept = float(dicom_raw.RescaleIntercept)\n",
    "\n",
    "        img_np = image.astype(np.float32)\n",
    "        img_np = img_np * slope + intercept\n",
    "\n",
    "        img_windowed = np.clip(img_np, center - width // 2, center + width // 2)\n",
    "        img_norm = (img_windowed - img_windowed.min()) / (img_windowed.max() - img_windowed.min() + 1e-5)\n",
    "\n",
    "        # ==== 4. Conversion en tenseur PyTorch + ajout canal (C, H, W)\n",
    "        img_tensor = torch.from_numpy(img_norm).float().unsqueeze(0)  # [1, H, W]\n",
    "\n",
    "        # ==== 5. Resize etc.\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        # ==== 6. Extraction des labels\n",
    "        label = torch.tensor(row[self.label_cols].values.astype(np.float32))\n",
    "\n",
    "        return img_tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "resize_transform = T.Resize((224, 224))\n",
    "\n",
    "train_dataset = RSNA_DICOM_Dataset(csv_path, dicom_dir, transform=resize_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import DenseNet121\n",
    "import torch.nn as nn\n",
    "\n",
    "model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=6).cuda()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch[0].cuda(), batch[1].cuda()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemorragie-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
