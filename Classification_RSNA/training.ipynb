{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Test to understand __get_item__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first_item: <class 'dict'>\n",
      "Keys in first_item: dict_keys(['image', 'label'])\n",
      "Shape of first_item['image']: (64, 64)\n",
      "Dataset length: 3\n",
      "Processing item 0\n",
      "Processing item 1\n",
      "Processing item 2\n",
      "images path : ['img1.dcm', 'img2.dcm', 'img3.dcm']\n",
      "labels : [0, 1, 0]\n",
      "Transforms : None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class MyMedicalDataset:\n",
    "    def __init__(self, image_paths, labels, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        # When you do dataset[i], this method is called with idx = i\n",
    "\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # In a real scenario, you'd load the image (e.g., DICOM with pydicom/MONAI LoadImage)\n",
    "        # For simplicity, let's pretend we load a dummy image\n",
    "        image_data = np.random.rand(64, 64) # Simulate loading an image\n",
    "\n",
    "        # Apply transforms if provided (e.g., MONAI transforms)\n",
    "        if self.transforms:\n",
    "            # MONAI transforms expect dictionaries\n",
    "            data_dict = {\"image\": image_data, \"label\": label}\n",
    "            data_dict = self.transforms(data_dict)\n",
    "            image_data = data_dict[\"image\"]\n",
    "            label = data_dict[\"label\"]\n",
    "\n",
    "        return {\"image\": image_data, \"label\": label}\n",
    "\n",
    "# --- Usage Example ---\n",
    "image_files = [\"img1.dcm\", \"img2.dcm\", \"img3.dcm\"]\n",
    "labels_data = [0, 1, 0]\n",
    "\n",
    "# Imagine some MONAI transforms here\n",
    "from monai.transforms import RandFlip, Compose, AsDiscrete, EnsureChannelFirstd\n",
    "\n",
    " #my_transforms = Compose([\n",
    "#     EnsureChannelFirstd(keys=\"image\"),\n",
    "#     RandFlip(prob=0.5, spatial_axis=None)\n",
    "    \n",
    "# ])\n",
    "\n",
    "\n",
    "dataset = MyMedicalDataset(image_files, labels_data, transforms=None)\n",
    "\n",
    "# This calls dataset.__getitem__(0)\n",
    "first_item = dataset[0]\n",
    "print(f\"Type of first_item: {type(first_item)}\")\n",
    "print(f\"Keys in first_item: {first_item.keys()}\")\n",
    "print(f\"Shape of first_item['image']: {first_item['image'].shape}\")\n",
    "\n",
    "# This calls dataset.__len__()\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "\n",
    "# This indirectly uses __getitem__ (and __len__) for iteration\n",
    "for i in range(len(dataset)):\n",
    "    item = dataset[i]\n",
    "    print(f\"Processing item {i}\")\n",
    "\n",
    "# Test on the class itself \n",
    "print(f\"images path : {dataset.image_paths}\" )\n",
    "print(f\"labels : {dataset.labels}\")\n",
    "print(f\"Transforms : {dataset.transforms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSNA class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pydicom\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import monai.transforms as T\n",
    "\n",
    "def safe_get_first(value, default):\n",
    "    try:\n",
    "        if isinstance(value, pydicom.multival.MultiValue):\n",
    "            return float(value[0])\n",
    "        else:\n",
    "            return float(value)\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "    \n",
    "\n",
    "class RSNA_DICOM_Dataset_V0(Dataset):\n",
    "    def __init__(self, csv_path, dicom_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.dicom_dir = Path(dicom_dir)\n",
    "        self.transform = transform\n",
    "        self.label_cols = [ 'any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        self.loader = T.LoadImage(image_only=False)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        dcm_path = self.dicom_dir / row['filename']\n",
    "        dcm = pydicom.dcmread(str(dcm_path))\n",
    "\n",
    "        # Load image\n",
    "        image, meta = self.loader(str(dcm_path)) # Using MONAI's LoadImage\n",
    "\n",
    "        dicom_raw = pydicom.dcmread(str(dcm_path))\n",
    "\n",
    "        center = safe_get_first(getattr(dcm, 'WindowCenter', 40), 40)\n",
    "        width = safe_get_first(getattr(dcm, 'WindowWidth', 80), 80)\n",
    "        slope = safe_get_first(getattr(dcm, 'RescaleSlope', 1), 1)\n",
    "        intercept = safe_get_first(getattr(dcm, 'RescaleIntercept', 0), 0)\n",
    "        \n",
    "\n",
    "        img_np = image.astype(np.float32)\n",
    "        img_np = img_np * slope + intercept\n",
    "\n",
    "        img_windowed = np.clip(img_np, center - width // 2, center + width // 2)\n",
    "        img_norm = (img_windowed - img_windowed.min()) / (img_windowed.max() - img_windowed.min() + 1e-5)\n",
    "\n",
    "        # ==== 4. Conversion en tenseur PyTorch + ajout canal (C, H, W)\n",
    "        img_tensor = torch.from_numpy(img_norm).float().unsqueeze(0)  # [1, H, W]\n",
    "\n",
    "        # ==== 5. Resize etc.\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        # ==== 6. Extraction des labels\n",
    "        label = torch.tensor(row[self.label_cols].values.astype(np.float32))\n",
    "        # print(\"DICOM path:\", dcm_path)\n",
    "        # print(\"Row filename:\", row['filename'])\n",
    "        # print(\"Row labels:\", row[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']])  \n",
    "        return img_tensor, label\n",
    "\n",
    "# Inspecting attr after 36th samples  in the dataset:\n",
    "\n",
    "import pydicom\n",
    "from pathlib import Path\n",
    "\n",
    "def safe_get_float(value, default):\n",
    "    if isinstance(value, pydicom.multival.MultiValue):\n",
    "        return float(value[0])\n",
    "    try:\n",
    "        return float(value)\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "# --- Paths ---\n",
    "csv_path = Path(\"/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/csv/train_fold0.csv\")\n",
    "dicom_dir = Path(\"/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/rsna-intracranial-hemorrhage-detection/stage_2_train\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Sample index\n",
    "i = 47\n",
    "dcm_path = Path(dicom_dir) / df.iloc[i][\"filename\"]\n",
    "dcm = pydicom.dcmread(str(dcm_path))\n",
    "dicom_raw = pydicom.dcmread(str(dcm_path))\n",
    "# Safe attribute reads\n",
    "center = (dicom_raw.WindowCenter)\n",
    "print(\"center\", center)\n",
    "width = (dicom_raw.WindowWidth)\n",
    "print(\"width\", width)\n",
    "slope = (dicom_raw.RescaleSlope)\n",
    "print(\"slope\", slope)\n",
    "intercept = float(dicom_raw.RescaleIntercept)\n",
    "print(\"intercept\", intercept)\n",
    "\n",
    "\n",
    "# Safe attribute reads\n",
    "center_2 = safe_get_float(getattr(dcm, 'WindowCenter', 40), 40)\n",
    "width_2 = safe_get_float(getattr(dcm, 'WindowWidth', 80), 80)\n",
    "slope_2 = safe_get_float(getattr(dcm, 'RescaleSlope', 1), 1)\n",
    "intercept_2 = safe_get_float(getattr(dcm, 'RescaleIntercept', 0), 0)\n",
    "\n",
    "print(\"center_2\", center_2)\n",
    "print(\"width_2\", width_2)\n",
    "print(\"slope_2\", slope_2)\n",
    "print(\"intercept_2\", intercept_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pydicom\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import monai.transforms as T\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class RSNA_DICOM_Dataset(Dataset):\n",
    "    def __init__(self, csv_path, dicom_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.dicom_dir = Path(dicom_dir)\n",
    "        self.transform = transform\n",
    "        self.label_cols = [ 'any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "        self.loader = T.LoadImage(image_only=False)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        dcm_path = self.dicom_dir / row['filename']\n",
    "        \n",
    "\n",
    "        # Load image\n",
    "        image, meta = self.loader(str(dcm_path)) # Using MONAI's LoadImage\n",
    "\n",
    "        #print(\"Image shape:\", image.shape)\n",
    "        # transform\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(image)\n",
    "            #print(\"Transformed image shape:\", img_tensor.shape)\n",
    "\n",
    "        # label extraction\n",
    "        label = torch.tensor(row[self.label_cols].values.astype(np.float32))\n",
    "        # print(\"DICOM path:\", dcm_path)\n",
    "        # print(\"Row filename:\", row['filename'])\n",
    "        # print(\"Row labels:\", row[['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']])  \n",
    "        return img_tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename            ID_357ebf7aa.dcm\n",
      "any                                1\n",
      "epidural                           0\n",
      "intraparenchymal                   0\n",
      "intraventricular                   1\n",
      "subarachnoid                       0\n",
      "subdural                           1\n",
      "PatientID                ID_00760731\n",
      "Name: 1001, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#VÃ©rifif alignement entre csv et get_item\n",
    "\n",
    "csv_path = Path(\"/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/csv/train_fold0.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(df.iloc[1001])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "80\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RSNA_DICOM_Dataset' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m csv_path = Path(\u001b[33m\"\u001b[39m\u001b[33m/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/csv/train_fold0.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m dicom_dir = Path(\u001b[33m\"\u001b[39m\u001b[33m/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/rsna-intracranial-hemorrhage-detection/stage_2_train\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m train_dataset = \u001b[43mRSNA_DICOM_Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdicom_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m(DEVICE)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of samples in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m image, label = train_dataset[\u001b[32m10000\u001b[39m]\n",
      "\u001b[31mAttributeError\u001b[39m: 'RSNA_DICOM_Dataset' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "window_preset = {\"window_center\": 40, \"window_width\": 80}\n",
    "\n",
    "print( window_preset[\"window_center\"] - window_preset[\"window_width\"]//2)\n",
    "print( window_preset[\"window_center\"] + window_preset[\"window_width\"]//2)\n",
    "train_transforms = T.Compose([\n",
    "    T.ScaleIntensityRange(\n",
    "        a_min=window_preset[\"window_center\"] - window_preset[\"window_width\"]//2,\n",
    "        a_max=window_preset[\"window_center\"] + window_preset[\"window_width\"]//2,\n",
    "        b_min=0.0,\n",
    "        b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "    T.EnsureChannelFirst(),\n",
    "    T.Resize((224, 224))\n",
    "])\n",
    "csv_path = Path(\"/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/csv/train_fold0.csv\")\n",
    "dicom_dir = Path(\"/home/tibia/Projet_Hemorragie/Seg_hemorragie/Classification_RSNA/data/rsna-intracranial-hemorrhage-detection/stage_2_train\")\n",
    "train_dataset = RSNA_DICOM_Dataset(csv_path, dicom_dir, transform=train_transforms)\n",
    "print(f\"Number of samples in the dataset: {len(train_dataset)}\")\n",
    "\n",
    "image, label = train_dataset[10000]\n",
    "print(image.shape)  # [1, 224, 224]\n",
    "print(label)  \n",
    "print(f\"Label shape: {label.shape}\")\n",
    "image_np = image.squeeze().numpy()  # Convert to numpy array for visualization\n",
    "print(f\"Image shape: {image_np.shape}\")  # Should be [1, 224, 224]\n",
    "# Affichage\n",
    "plt.imshow(image_np, cmap='gray')\n",
    "plt.title(f\"Labels: {label.tolist()}\")\n",
    "plt.axis('off')\n",
    "plt.show()  \n",
    "\n",
    "#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of Batches in the dataset: 16859\n",
      "DenseNet121(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (class_layers): Sequential(\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (out): Linear(in_features=1024, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "rÃ©partition des poids : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.networks.nets import densenet121\n",
    "from monai.transforms import Compose, Resize, ToTensor\n",
    "from monai.data import DataLoader, PersistentDataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# === Hyperparams ===\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LR = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,persistent_workers= True,pin_memory=True)\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Number of Batches in the dataset: {len(train_loader)}\")\n",
    "\n",
    "# === Model ===\n",
    "model = densenet121(spatial_dims=2, in_channels=1, out_channels=NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "print (model)\n",
    "# === Loss (InspirÃ© Al )\n",
    "\n",
    "pos_weights = torch.tensor([1.0] * NUM_CLASSES, dtype=torch.float).to(DEVICE)\n",
    "print(f\"rÃ©partition des poids : {pos_weights}\")\n",
    "loss_fn= nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "# === Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: tensor([0., 0., 1., 1., 1., 1.])\n",
      "Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float,end:float,device:torch.device=None):\n",
    "    total_time=end-start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Renvoie l'accuracy multilabel (exact match pour chaque label indÃ©pendamment).\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(y_pred) > threshold\n",
    "    #print(f\"preds: {preds}\")\n",
    "    correct = (preds == y_true.bool()).float()\n",
    "    #print(f\"correct: {correct}\")\n",
    "    return correct.mean().item()\n",
    "\n",
    "y_pred= torch.tensor([0, 0, 1, 1, 1, 1], dtype=torch.float)\n",
    "print(\"y_pred:\", y_pred)\n",
    "y_true = torch.tensor([1, 0, 1, 0, 1, 0], dtype=torch.float)\n",
    "accuracy = compute_accuracy(y_pred, y_true)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:torch.nn.Module,\n",
    "                dataloader:torch.utils.data.DataLoader,\n",
    "                loss_fn:torch.nn.Module,\n",
    "                optimizer:torch.optim,\n",
    "                compute_accuracy,\n",
    "                device:torch.device=DEVICE):\n",
    "   \n",
    "    train_loss,train_acc=0,0\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "     \n",
    "      X,y=X.to(device),y.to(device)\n",
    "\n",
    "      #1. forward pass (output the raw logits from the model )\n",
    "      y_pred=model(X)\n",
    "\n",
    "      #2. Calculate loss and accuracy (per batch)\n",
    "      loss=loss_fn(y_pred,y)\n",
    "      train_loss += loss\n",
    "      train_acc += compute_accuracy(y_pred=y_pred,y_true=y) # go from logits -> prediction labels\n",
    "\n",
    "      #3. Optimizer zero grad \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      #4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      #5. Optimizer step\n",
    "      \n",
    "      optimizer.step()\n",
    "      #Divide total train loss and acc by lenght of train dataloader\n",
    "    \n",
    "    if (batch % 400 == 0):\n",
    "      print(f\"Looked at {batch * len(X)}/{len(dataloader.dataset)} samples\")\n",
    "      \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.4f}\")\n",
    "\n",
    "\n",
    "def val_step(model:torch.nn.Module,\n",
    "                dataloader:torch.utils.data.DataLoader,\n",
    "                loss_fn:torch.nn.Module,\n",
    "                compute_accuracy,\n",
    "                device:torch.device=DEVICE):\n",
    "    \"\"\"Performs a testing loop step on model going over data_loader\"\"\"\n",
    "   \n",
    "    test_loss,test_acc=0,0\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      for batch,(X_test,y_test) in enumerate(dataloader):\n",
    "     \n",
    "        X_test,y_test=X_test.to(device),y_test.to(device)\n",
    "\n",
    "      #1. forward pass (output the raw logits from the model )\n",
    "        test_pred=model(X_test)\n",
    "\n",
    "      #2. Calculate loss and accuracy (per batch)\n",
    "        loss=loss_fn(test_pred,y_test)\n",
    "        test_loss += loss\n",
    "        test_acc += compute_accuracy(y_true=y_test,y_pred=test_pred) # go from logits -> prediction labels\n",
    "     \n",
    "      if (batch % 400 == 0):\n",
    "        print(f\"Looked at {batch * len(X_test)}/{len(dataloader.dataset)} samples\")\n",
    "    #Divide total test loss and acc by lenght of test dataloader\n",
    "      test_loss /= len(dataloader)\n",
    "      test_acc /= len(dataloader)\n",
    "\n",
    "      print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS)):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m               \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m               \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m               \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m               \u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m end_time = timer()\n\u001b[32m     20\u001b[39m total_train_time = print_train_time(start_time, end_time, DEVICE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, dataloader, loss_fn, optimizer, compute_accuracy, device)\u001b[39m\n\u001b[32m      8\u001b[39m train_loss,train_acc=\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m\n\u001b[32m     11\u001b[39m model.train()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch,(X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     15\u001b[39m   X,y=X.to(device),y.to(device)\n\u001b[32m     17\u001b[39m   \u001b[38;5;66;03m#1. forward pass (output the raw logits from the model )\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:481\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    479\u001b[39m         \u001b[38;5;28mself\u001b[39m._iterator = \u001b[38;5;28mself\u001b[39m._get_iterator()\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1222\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._reset\u001b[39m\u001b[34m(self, loader, first_iter)\u001b[39m\n\u001b[32m   1220\u001b[39m resume_iteration_cnt = \u001b[38;5;28mself\u001b[39m._num_workers\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     return_idx, return_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils.worker._ResumeIteration):\n\u001b[32m   1224\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1402\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1401\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1403\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1404\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1243\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1231\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1232\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1241\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1246\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1247\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1248\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.9/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # === Training Loop ===\n",
    "# from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    train_step(model=model,\n",
    "               dataloader=train_loader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               compute_accuracy=compute_accuracy,\n",
    "               device=DEVICE)\n",
    "    \n",
    "\n",
    "end_time = timer()\n",
    "total_train_time = print_train_time(start_time, end_time, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the validation dataset: 134788\n"
     ]
    }
   ],
   "source": [
    "  ## Testing\n",
    "# --- Paths ---\n",
    "csv_path = \"/home/tibia/Projet_Hemorragie/Classification/RSNA2019_Intracranial-Hemorrhage-Detection/2DNet/data/csv/val_fold0.csv\"\n",
    "dicom_dir = \"/home/tibia/Projet_Hemorragie/Classification/RSNA2019_Intracranial-Hemorrhage-Detection/2DNet/data/rsna-intracranial-hemorrhage-detection/stage_2_train\"\n",
    "\n",
    "val_dataset = RSNA_DICOM_Dataset(csv_path, dicom_dir, transform=resize_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "print(f\"Number of samples in the validation dataset: {len(val_dataset)}\")\n",
    "# Testing the model\n",
    "print(\"Testing the model...\")\n",
    "# test_step(model=model,\n",
    "#           dataloader=val_loader,\n",
    "#           loss_fn=loss_fn,\n",
    "#           compute_accuracy=compute_accuracy,\n",
    "#           device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemorragie-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
