{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import PersistentDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import monai.transforms as T\n",
    "import torch\n",
    "# Using MONAI for medical imaging tasks\n",
    "# ---- Config ----\n",
    "csv_path = Path(\"/home/tibia/Projet_Hemorragie/MBH_label_case/splits/train_split.csv\")\n",
    "nii_dir = Path(\"/home/tibia/Projet_Hemorragie/MBH_label_case\")\n",
    "cache_dir = Path(\"./persistent_cache/3D_train_cache\")  \n",
    "# Ensure cache directory exists\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "label_cols = ['any', 'epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ---- Build MONAI-style data list ----\n",
    "data_list = [\n",
    "    {\n",
    "        \"image\": str(nii_dir / f\"{row['patientID_studyID']}.nii.gz\"),\n",
    "        \"label\": np.array([row[col] for col in label_cols], dtype=np.float32)\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "#print (data_list[:5] ) # Print first 5 entries for debugging\n",
    "# ---- Transforms ----\n",
    "window_preset = {\"window_center\": 40, \"window_width\": 80}\n",
    "\n",
    "\n",
    "window_preset = {\"window_center\": 40, \"window_width\": 80}\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    # Load image only\n",
    "    T.LoadImaged(keys=[\"image\"], image_only=True),  \n",
    "    T.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    \n",
    "    # Harmonisation spatiale\n",
    "    T.Orientationd(keys=[\"image\"], axcodes='RAS'),  # standard orientation\n",
    "    T.Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),  # isometric voxels\n",
    "    \n",
    "    # Padding/cropping\n",
    "   \n",
    "    T.ResizeD(keys=[\"image\"], spatial_size=(224, 224, -1 )), \n",
    "    T.SpatialPadd(keys=[\"image\"], spatial_size=(128, 128, 64)) ,# Padding to ensure consistent size : on garde toujours tous les slices mais on ajoute du vide\n",
    "\n",
    "    # Intensity\n",
    "    T.ScaleIntensityRanged(\n",
    "        keys=[\"image\"],\n",
    "        a_min=window_preset[\"window_center\"] - window_preset[\"window_width\"] // 2,\n",
    "        a_max=window_preset[\"window_center\"] + window_preset[\"window_width\"] // 2,\n",
    "        b_min=0.0,\n",
    "        b_max=1.0,\n",
    "        clip=True\n",
    "    ),\n",
    "\n",
    "    # Augmentations\n",
    "    T.RandFlipd(keys=[\"image\"], spatial_axis=[0, 1, 2], prob=0.5),\n",
    "    T.RandRotate90d(keys=[\"image\"], spatial_axes=(0, 1), prob=0.5),\n",
    "    T.RandScaleIntensityd(keys=[\"image\"], factors=0.1, prob=0.5),\n",
    "    T.RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n",
    "\n",
    "    # Final tensor\n",
    "    T.ToTensord(keys=[\"image\", \"label\"])\n",
    "])\n",
    "\n",
    "for data in data_list:\n",
    "    try:\n",
    "        sample = train_transforms(data)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading: {data['image']}\")\n",
    "        raise e\n",
    "# ---- PersistentDataset ----\n",
    "train_dataset = PersistentDataset(\n",
    "    data=data_list,\n",
    "    transform=train_transforms,\n",
    "    cache_dir=str(cache_dir),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\" Dataset ready with {len(train_dataset)} samples and cached transforms at {cache_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of Batches in the dataset: 40\n",
      "répartition des poids : tensor([1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from monai.networks.nets import densenet121,SEResNet50,ResNet\n",
    "from monai.transforms import Compose, Resize, ToTensor\n",
    "from monai.data import DataLoader, PersistentDataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# === Hyperparams ===\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LR = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8,persistent_workers= True,pin_memory=True)\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Number of Batches in the dataset: {len(train_loader)}\")\n",
    "\n",
    "# === Model ===\n",
    "model = ResNet(\n",
    "    block='basic',           # BasicBlock for ResNet18/34\n",
    "    layers=[2, 2, 2, 2],    # ResNet18 architecture\n",
    "    block_inplanes=[64, 128, 256, 512],\n",
    "    spatial_dims=3,\n",
    "    n_input_channels=1,     # Your grayscale input\n",
    "    num_classes=NUM_CLASSES,\n",
    "    conv1_t_size=7,\n",
    "    conv1_t_stride=2\n",
    ")\n",
    "# model = SEResNet50(\n",
    "#     spatial_dims=2,         # Because you work with 2D CT slices\n",
    "#     in_channels=1,          # 1 channel for grayscale CT (unless you use 3-slice input, see tip below)\n",
    "#     num_classes= NUM_CLASSES,          # Set this to number of hemorrhage types you want to classify\n",
    "#     pretrained=False,       # Can be True if input has 3 channels and you're okay fine-tuning from ImageNet\n",
    "#     dropout_prob=0.2,       # Helps regularize on smaller datasets\n",
    "#     reduction=16,           # Default for Squeeze-and-Excitation; works well\n",
    "#     input_3x3=True,         # Enables better local feature extraction at first layer\n",
    "#     downsample_kernel_size=3  # Slightly better spatial feature preservation\n",
    "#)\n",
    "#model = densenet121(spatial_dims=2, in_channels=1, out_channels=NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "#print (model)\n",
    "# === Loss (Inspiré Al )\n",
    "\n",
    "pos_weights = torch.tensor([1.0] * NUM_CLASSES, dtype=torch.float).to(DEVICE)\n",
    "print(f\"répartition des poids : {pos_weights}\")\n",
    "loss_fn= nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "# === Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /store/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [32, 6]                   --\n",
       "├─Conv3d: 1-1                            [32, 64, 112, 112, 32]    21,952\n",
       "├─BatchNorm3d: 1-2                       [32, 64, 112, 112, 32]    128\n",
       "├─ReLU: 1-3                              [32, 64, 112, 112, 32]    --\n",
       "├─MaxPool3d: 1-4                         [32, 64, 56, 56, 16]      --\n",
       "├─Sequential: 1-5                        [32, 64, 56, 56, 16]      --\n",
       "│    └─ResNetBlock: 2-1                  [32, 64, 56, 56, 16]      --\n",
       "│    │    └─Conv3d: 3-1                  [32, 64, 56, 56, 16]      110,592\n",
       "│    │    └─BatchNorm3d: 3-2             [32, 64, 56, 56, 16]      128\n",
       "│    │    └─ReLU: 3-3                    [32, 64, 56, 56, 16]      --\n",
       "│    │    └─Conv3d: 3-4                  [32, 64, 56, 56, 16]      110,592\n",
       "│    │    └─BatchNorm3d: 3-5             [32, 64, 56, 56, 16]      128\n",
       "│    │    └─ReLU: 3-6                    [32, 64, 56, 56, 16]      --\n",
       "│    └─ResNetBlock: 2-2                  [32, 64, 56, 56, 16]      --\n",
       "│    │    └─Conv3d: 3-7                  [32, 64, 56, 56, 16]      110,592\n",
       "│    │    └─BatchNorm3d: 3-8             [32, 64, 56, 56, 16]      128\n",
       "│    │    └─ReLU: 3-9                    [32, 64, 56, 56, 16]      --\n",
       "│    │    └─Conv3d: 3-10                 [32, 64, 56, 56, 16]      110,592\n",
       "│    │    └─BatchNorm3d: 3-11            [32, 64, 56, 56, 16]      128\n",
       "│    │    └─ReLU: 3-12                   [32, 64, 56, 56, 16]      --\n",
       "├─Sequential: 1-6                        [32, 128, 28, 28, 8]      --\n",
       "│    └─ResNetBlock: 2-3                  [32, 128, 28, 28, 8]      --\n",
       "│    │    └─Conv3d: 3-13                 [32, 128, 28, 28, 8]      221,184\n",
       "│    │    └─BatchNorm3d: 3-14            [32, 128, 28, 28, 8]      256\n",
       "│    │    └─ReLU: 3-15                   [32, 128, 28, 28, 8]      --\n",
       "│    │    └─Conv3d: 3-16                 [32, 128, 28, 28, 8]      442,368\n",
       "│    │    └─BatchNorm3d: 3-17            [32, 128, 28, 28, 8]      256\n",
       "│    │    └─Sequential: 3-18             [32, 128, 28, 28, 8]      8,576\n",
       "│    │    └─ReLU: 3-19                   [32, 128, 28, 28, 8]      --\n",
       "│    └─ResNetBlock: 2-4                  [32, 128, 28, 28, 8]      --\n",
       "│    │    └─Conv3d: 3-20                 [32, 128, 28, 28, 8]      442,368\n",
       "│    │    └─BatchNorm3d: 3-21            [32, 128, 28, 28, 8]      256\n",
       "│    │    └─ReLU: 3-22                   [32, 128, 28, 28, 8]      --\n",
       "│    │    └─Conv3d: 3-23                 [32, 128, 28, 28, 8]      442,368\n",
       "│    │    └─BatchNorm3d: 3-24            [32, 128, 28, 28, 8]      256\n",
       "│    │    └─ReLU: 3-25                   [32, 128, 28, 28, 8]      --\n",
       "├─Sequential: 1-7                        [32, 256, 14, 14, 4]      --\n",
       "│    └─ResNetBlock: 2-5                  [32, 256, 14, 14, 4]      --\n",
       "│    │    └─Conv3d: 3-26                 [32, 256, 14, 14, 4]      884,736\n",
       "│    │    └─BatchNorm3d: 3-27            [32, 256, 14, 14, 4]      512\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 14, 14, 4]      --\n",
       "│    │    └─Conv3d: 3-29                 [32, 256, 14, 14, 4]      1,769,472\n",
       "│    │    └─BatchNorm3d: 3-30            [32, 256, 14, 14, 4]      512\n",
       "│    │    └─Sequential: 3-31             [32, 256, 14, 14, 4]      33,536\n",
       "│    │    └─ReLU: 3-32                   [32, 256, 14, 14, 4]      --\n",
       "│    └─ResNetBlock: 2-6                  [32, 256, 14, 14, 4]      --\n",
       "│    │    └─Conv3d: 3-33                 [32, 256, 14, 14, 4]      1,769,472\n",
       "│    │    └─BatchNorm3d: 3-34            [32, 256, 14, 14, 4]      512\n",
       "│    │    └─ReLU: 3-35                   [32, 256, 14, 14, 4]      --\n",
       "│    │    └─Conv3d: 3-36                 [32, 256, 14, 14, 4]      1,769,472\n",
       "│    │    └─BatchNorm3d: 3-37            [32, 256, 14, 14, 4]      512\n",
       "│    │    └─ReLU: 3-38                   [32, 256, 14, 14, 4]      --\n",
       "├─Sequential: 1-8                        [32, 512, 7, 7, 2]        --\n",
       "│    └─ResNetBlock: 2-7                  [32, 512, 7, 7, 2]        --\n",
       "│    │    └─Conv3d: 3-39                 [32, 512, 7, 7, 2]        3,538,944\n",
       "│    │    └─BatchNorm3d: 3-40            [32, 512, 7, 7, 2]        1,024\n",
       "│    │    └─ReLU: 3-41                   [32, 512, 7, 7, 2]        --\n",
       "│    │    └─Conv3d: 3-42                 [32, 512, 7, 7, 2]        7,077,888\n",
       "│    │    └─BatchNorm3d: 3-43            [32, 512, 7, 7, 2]        1,024\n",
       "│    │    └─Sequential: 3-44             [32, 512, 7, 7, 2]        132,608\n",
       "│    │    └─ReLU: 3-45                   [32, 512, 7, 7, 2]        --\n",
       "│    └─ResNetBlock: 2-8                  [32, 512, 7, 7, 2]        --\n",
       "│    │    └─Conv3d: 3-46                 [32, 512, 7, 7, 2]        7,077,888\n",
       "│    │    └─BatchNorm3d: 3-47            [32, 512, 7, 7, 2]        1,024\n",
       "│    │    └─ReLU: 3-48                   [32, 512, 7, 7, 2]        --\n",
       "│    │    └─Conv3d: 3-49                 [32, 512, 7, 7, 2]        7,077,888\n",
       "│    │    └─BatchNorm3d: 3-50            [32, 512, 7, 7, 2]        1,024\n",
       "│    │    └─ReLU: 3-51                   [32, 512, 7, 7, 2]        --\n",
       "├─AdaptiveAvgPool3d: 1-9                 [32, 512, 1, 1, 1]        --\n",
       "├─Linear: 1-10                           [32, 6]                   3,078\n",
       "==========================================================================================\n",
       "Total params: 33,163,974\n",
       "Trainable params: 33,163,974\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.TERABYTES): 1.54\n",
       "==========================================================================================\n",
       "Input size (MB): 411.04\n",
       "Forward/backward pass size (MB): 22427.47\n",
       "Params size (MB): 132.66\n",
       "Estimated Total Size (MB): 22971.17\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try : \n",
    "    ! pip install torchinfo\n",
    "\n",
    "except:\n",
    "    print(\"torchinfo is already installed or installation failed.\")\n",
    "    \n",
    "import torchinfo\n",
    "from torchinfo import summary\n",
    "# Display model summary\n",
    "model = model.to(DEVICE)\n",
    "summary(model, input_size=(BATCH_SIZE, 1, 224, 224,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start:float,end:float,device:torch.device=None):\n",
    "    total_time=end-start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Renvoie l'accuracy multilabel (exact match pour chaque label indépendamment).\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(y_pred) > threshold\n",
    "    #print(f\"preds: {preds}\")\n",
    "    correct = (preds == y_true.bool()).float()\n",
    "    #print(f\"correct: {correct}\")\n",
    "    return correct.mean().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:torch.nn.Module,\n",
    "                dataloader:torch.utils.data.DataLoader,\n",
    "                loss_fn:torch.nn.Module,\n",
    "                optimizer:torch.optim,\n",
    "                device:torch.device=DEVICE):\n",
    "   \n",
    "    train_loss=0\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "      X = batch[\"image\"].to(device)\n",
    "      y = batch[\"label\"].to(device)\n",
    "    \n",
    "      #1. forward pass (output the raw logits from the model )\n",
    "      y_pred=model(X)\n",
    "\n",
    "      #2. Calculate loss and accuracy (per batch)\n",
    "      loss=loss_fn(y_pred,y)\n",
    "      train_loss += loss\n",
    "\n",
    "\n",
    "      #3. Optimizer zero grad \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      #4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      #5. Optimizer step\n",
    "      \n",
    "      optimizer.step()\n",
    "      #Divide total train loss and acc by lenght of train dataloader\n",
    "    \n",
    "      if (i% 400 == 0):\n",
    "        print(f\"Looked at {i * len(X)}/{len(dataloader.dataset)} samples\")\n",
    "      \n",
    "    train_loss /= len(dataloader)\n",
    "   \n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} \")\n",
    "\n",
    "\n",
    "def val_step(model:torch.nn.Module,\n",
    "                dataloader:torch.utils.data.DataLoader,\n",
    "                loss_fn:torch.nn.Module,\n",
    "                device:torch.device=DEVICE):\n",
    "    \"\"\"Performs a testing loop step on model going over data_loader\"\"\"\n",
    "   \n",
    "    test_loss=0\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "      for batch,(X_test,y_test) in enumerate(dataloader):\n",
    "     \n",
    "        X_test,y_test=X_test.to(device),y_test.to(device)\n",
    "\n",
    "      #1. forward pass (output the raw logits from the model )\n",
    "        test_pred=model(X_test)\n",
    "\n",
    "      #2. Calculate loss and accuracy (per batch)\n",
    "        loss=loss_fn(test_pred,y_test)\n",
    "        test_loss += loss\n",
    "        test_acc += compute_accuracy(y_true=y_test,y_pred=test_pred) # go from logits -> prediction labels\n",
    "     \n",
    "        if (batch % 400 == 0):\n",
    "          print(f\"Looked at {batch * len(X_test)}/{len(dataloader.dataset)} samples\")\n",
    "    #Divide total test loss and acc by lenght of test dataloader\n",
    "      test_loss /= len(dataloader)\n",
    "   \n",
    "\n",
    "      print(f\"Test loss: {test_loss:.5f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/transform.py\", line 141, in apply_transform\n    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/transform.py\", line 98, in _apply_transform\n    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n                                                                               ^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/io/dictionary.py\", line 163, in __call__\n    data = self._loader(d[key], reader)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/io/array.py\", line 264, in __call__\n    img = reader.read(filename)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/image_reader.py\", line 491, in read\n    ds = pydicom.dcmread(fp=name, **kwargs_)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/pydicom/filereader.py\", line 1042, in dcmread\n    fp = open(fp, \"rb\")\n         ^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/home/tibia/Projet_Hemorragie/MBH_label_case/ID_4e069b3d_ID_0320ad6a17'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 108, in __getitem__\n    return self._transform(index)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 412, in _transform\n    pre_random_item = self._cachecheck(self.data[index])\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 385, in _cachecheck\n    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 323, in _pre_transform\n    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/compose.py\", line 335, in __call__\n    result = execute_compose(\n             ^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/compose.py\", line 111, in execute_compose\n    data = apply_transform(\n           ^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/transform.py\", line 171, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7fbaea698050>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS)):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m               \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m               \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m               \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[43m               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m end_time = timer()\n\u001b[32m     20\u001b[39m total_train_time = print_train_time(start_time, end_time, DEVICE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, dataloader, loss_fn, optimizer, device)\u001b[39m\n\u001b[32m      7\u001b[39m train_loss=\u001b[32m0\u001b[39m\n\u001b[32m     10\u001b[39m model.train()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m  \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m  \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1465\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1464\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/_utils.py:715\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    712\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mRuntimeError\u001b[39m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/transform.py\", line 141, in apply_transform\n    return _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/transform.py\", line 98, in _apply_transform\n    return transform(data, lazy=lazy) if isinstance(transform, LazyTrait) else transform(data)\n                                                                               ^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/io/dictionary.py\", line 163, in __call__\n    data = self._loader(d[key], reader)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/io/array.py\", line 264, in __call__\n    img = reader.read(filename)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/image_reader.py\", line 491, in read\n    ds = pydicom.dcmread(fp=name, **kwargs_)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/pydicom/filereader.py\", line 1042, in dcmread\n    fp = open(fp, \"rb\")\n         ^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/home/tibia/Projet_Hemorragie/MBH_label_case/ID_4e069b3d_ID_0320ad6a17'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 108, in __getitem__\n    return self._transform(index)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 412, in _transform\n    pre_random_item = self._cachecheck(self.data[index])\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 385, in _cachecheck\n    _item_transformed = self._pre_transform(deepcopy(item_transformed))  # keep the original hashed\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/data/dataset.py\", line 323, in _pre_transform\n    item_transformed = self.transform(item_transformed, end=first_random, threading=True)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/compose.py\", line 335, in __call__\n    result = execute_compose(\n             ^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/compose.py\", line 111, in execute_compose\n    data = apply_transform(\n           ^^^^^^^^^^^^^^^^\n  File \"/home/tibia/Projet_Hemorragie/hemorragie-env/lib/python3.12/site-packages/monai/transforms/transform.py\", line 171, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7fbaea698050>\n"
     ]
    }
   ],
   "source": [
    "# # === Training Loop ===\n",
    "# from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    train_step(model=model,\n",
    "               dataloader=train_loader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "     \n",
    "               device=DEVICE)\n",
    "    \n",
    "\n",
    "end_time = timer()\n",
    "total_train_time = print_train_time(start_time, end_time, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemorragie-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
